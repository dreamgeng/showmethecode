# showmethecode
* 项目地址：https://github.com/Show-Me-the-Code/show-me-the-code
* 此仓库只作为自己平时刷题记录
* 会记录一些算法思想和题解方法

## 极客时间－数据结构与算法之美

### 复杂度分析(极客０３，０４)

#### 什么是复杂度分析？
* 数据结构和算法解决是“如何让计算机更快时间、更省空间的解决问题”。
* 因此需从执行时间和占用空间两个维度来评估数据结构和算法的性能。
* 分别用时间复杂度和空间复杂度两个概念来描述性能问题，二者统称为复杂度
* 复杂度描述的是算法执行时间（或占用空间）与数据规模的增长关系。

#### 为什么要进行复杂度分析？
* 和性能测试相比，复杂度分析有不依赖执行环境、成本低、效率高、易操作、指导性强的特点。
* 掌握复杂度分析，将能编写出性能更优的代码，有利于降低系统开发和维护成本。

#### 如何进行复杂度分析？
1. 大O表示法
   * 来源
     算法的执行时间与每行代码的执行次数成正比，用T(n) = O(f(n))表示，其中T(n)表示算法执行总时间，f(n)表示每行代码执行总次数，而n往往表示数据的规模。
   * 特点
     以时间复杂度为例，由于时间复杂度描述的是算法执行时间与数据规模的增长变化趋势，所以常量阶、低阶以及系数实际上对这种增长趋势不产决定性影响，所以在做时间复杂度分析时忽略这些项。

2. 复杂度分析法则
   * 单段代码看高频：比如循环。
   * 多段代码取最大：比如一段代码中有单循环和多重循环，那么取多重循环的复杂度。
   * 嵌套代码求乘积：比如递归、多重循环等
   * 多个规模求加法：比如方法有两个参数控制两个循环的次数，那么这时就取二者复杂度相加。

#### 常用的复杂度级别？
多项式阶：随着数据规模的增长，算法的执行时间和空间占用，按照多项式的比例增长。包括，
O(1)（常数阶）、O(logn)（对数阶）、O(n)（线性阶）、O(nlogn)（线性对数阶）、O(n^2)（平方阶）、O(n^3)（立方阶）
非多项式阶：随着数据规模的增长，算法的执行时间和空间占用暴增，这类算法性能极差。包括，
O(2^n)（指数阶）、O(n!)（阶乘阶）

![](/home/dreamgeng/Documents/dreamgeng/showmethecode/复杂度.jpg)

常见的复杂度并不多，从低阶到高阶有：O(1)、O(logn)、O(n)、O(nlogn)、O(n2 )

#### 如何掌握好复杂度分析方法？
复杂度分析关键在于多练，所谓孰能生巧。

#### 复杂度分析的4个概念
1. 最坏情况时间复杂度：代码在最理想情况下执行的时间复杂度。

2. 最好情况时间复杂度：代码在最坏情况下执行的时间复杂度。

3. 平均时间复杂度：用代码在所有情况下执行的次数的加权平均值表示。

4. 均摊时间复杂度：在代码执行的所有复杂度情况中绝大部分是低级别的复杂度，个别情况是高级别复杂度且发生具有时序关系时，可以将个别高级别复杂度均摊到低级别复杂度上。基本上均摊结果就等于低级别复杂度。

#### 为什么要引入这4个概念？
1. 同一段代码在不同情况下时间复杂度会出现量级差异，为了更全面，更准确的描述代码的时间复杂度，所以引入这4个概念。

2. 代码复杂度在不同情况下出现量级差别时才需要区别这四种复杂度。大多数情况下，是不需要区别分析它们的。

#### 如何分析平均、均摊时间复杂度？
1. 平均时间复杂度
   代码在不同情况下复杂度出现量级差别，则用代码所有可能情况下执行次数的加权平均值表示。

2. 均摊时间复杂度
   两个条件满足时使用：1）代码在绝大多数情况下是低级别复杂度，只有极少数情况是高级别复杂度；2）低级别和高级别复杂度出现具有时序规律。均摊结果一般都等于低级别复杂度。

### 数组（极客05）

数组看起来简单基础，但是很多人没有理解这个数据结构的精髓。带着为什么数组要从0开始编号，而不是从1开始的问题，进入主题。

#### **数组如何实现随机访问**

1.  数组是一种**线性表**数据结构，用**连续的存储空间存储相同类型数据**

   - 线性表：数组、链表、队列、栈 
   - 非线性表：树 图
   - 连续的内存空间、相同的数据，所以数组可以随机访问，但对数组进行删除插入，为了保证数组的连续性，就要做大量的数据搬移工

2. 数组如何实现下标随机访问

   * 引入数组在内存中的分配图，得出寻址公式

   * 一维数组：`a[k]_address = base_address + k * type_size`

   * 二维数组：对于 m * n 的数组，a [ i ][ j ] (i < m,j < n)的地址为：

     `address = base_address + ( i * n + j) * type_size`

   *  纠正数组和链表的错误认识。数组的查找操作时间复杂度并不是O(1)。即便是排好的数组，用二分查找，时间复杂度也是O（logn）。
       正确表述：数组支持随机访问，根据下标随机访问的时间复杂度为O（1）

3. 低效的插入和删除

   * 插入：插入最后最好O(1)，插入开头 最坏O(n) ，平均O(n)
   * 但是数组若无序，插入新的元素时，可以将第K个位置元素移动到数组末尾，把新的元素，插入到第k个位置，此处复杂度为O(1)。
   * 删除：从最后删除最好O(1) ，从头删除最坏O(n) ，平均O(n)
   * 多次删除集中在一起，提高删除效率
     记录下已经被删除的数据，每次的删除操作并不是搬移数据，只是记录数据已经被删除，当数组没有更多的存储空间时，再触发一次真正的删除操作。即JVM标记清除垃圾回收算法。

4. 警惕数组的访问越界问题
   用C语言循环越界访问的例子说明访问越界的bug。此例在《C陷阱与缺陷》出现过，很惭愧，看过但是现在也只有一丢丢印象。翻了下书，替作者加上一句话：如果用来编译这段程序的编译器按照内存地址递减的方式给变量分配内存，那么内存中的i将会被置为0，则为死循环永远出不去。

5. 容器能否完全替代数组
   相比于数字，java中的ArrayList封装了数组的很多操作，并支持动态扩容。但一旦超过存储容量，扩容时比较耗内存，因为涉及到内存申请和数据搬移。
   数组适合的场景：
   1）    Java ArrayList 的使用涉及装箱拆箱，有一定的性能损耗，如果特别关注性能，可以考虑数组
   2）    若数据大小事先已知，并且涉及的数据操作非常简单，可以使用数组
   3）    表示多维数组时，数组往往更加直观。
   4）    业务开发容器即可；底层开发，如网络框架，性能优化，选择数组。

6. 解答开篇问题
   1）    从偏移角度理解a[0] ，0实际为偏移量，如果从1计数，a[k]的内存地址变为`a[k]_address = base_address + (k-1)*type_size`，会多出K-1。增加cpu负担。
   2）    也有一定的历史原因

### 如何优雅的写出链表代码？6大学习技巧(极客07)

#### 理解指针或引用的含义
1.含义：将某个变量（对象）赋值给指针（引用），实际上就是就是将这个变量（对象）的地址赋值给指针（引用）。
2.示例：

```
p—>next = q; 表示p节点的后继指针存储了q节点的内存地址。
p—>next = p—>next—>next; 表示p节点的后继指针存储了p节点的下下个节点的内存地址。
```

#### 警惕指针丢失和内存泄漏（单链表）
1.插入节点
在节点a和节点b之间插入节点x，b是a的下一节点，p指针指向节点a，则造成指针丢失和内存泄漏的代码：`p—>next = x;x—>next = p—>next; `显然这会导致x节点的后继指针指向自身。
正确的写法是2句代码交换顺序，即：`x—>next = p—>next; p—>next = x;`
2.删除节点
在节点a和节点b之间删除节点b，b是a的下一节点，p指针指向节点a：`p—>next = p—>next—>next;`

#### 利用“哨兵”简化实现难度
1.什么是“哨兵”？
链表中的“哨兵”节点是解决边界问题的，不参与业务逻辑。如果我们引入“哨兵”节点，则不管链表是否为空，head指针都会指向这个“哨兵”节点。我们把这种有“哨兵”节点的链表称为带头链表，相反，没有“哨兵”节点的链表就称为不带头链表。
2.未引入“哨兵”的情况
如果在p节点后插入一个节点，只需2行代码即可搞定：

```
new_node—>next = p—>next;
p—>next = new_node;
```

但，若向空链表中插入一个节点，则代码如下：

```
if(head == null){
head = new_node;
}
```

如果要删除节点p的后继节点，只需1行代码即可搞定：
`p—>next = p—>next—>next;`
但，若是删除链表的最后一个节点（链表中只剩下这个节点），则代码如下：

```
if(head—>next == null){
head = null;
}
```

从上面的情况可以看出，针对链表的插入、删除操作，需要对插入第一个节点和删除最后一个节点的情况进行特殊处理。这样代码就会显得很繁琐，所以引入“哨兵”节点来解决这个问题。
#### 引入“哨兵”的情况
“哨兵”节点不存储数据，无论链表是否为空，head指针都会指向它，作为链表的头结点始终存在。这样，插入第一个节点和插入其他节点，删除最后一个节点和删除其他节点都可以统一为相同的代码实现逻辑了。
#### “哨兵”还有哪些应用场景？
这个知识有限，暂时想不出来呀！但总结起来，哨兵最大的作用就是简化边界条件的处理。

#### 重点留意边界条件处理
经常用来检查链表是否正确的边界4个边界条件：
1.如果链表为空时，代码是否能正常工作？
2.如果链表只包含一个节点时，代码是否能正常工作？
3.如果链表只包含两个节点时，代码是否能正常工作？
4.代码逻辑在处理头尾节点时是否能正常工作？

#### 举例画图，辅助思考
核心思想：释放脑容量，留更多的给逻辑思考，这样就会感觉到思路清晰很多。

#### 多写多练，没有捷径
#### 5个常见的链表操作：(见王争老师github)
1.单链表反转
2.链表中环的检测
3.两个有序链表合并
4.删除链表倒数第n个节点
5.求链表的中间节点

### 栈：如何实现浏览器的前进和后退功能？(极客08)

#### 如何理解“栈”？

后进者先出，先进者后出，这就是典型的“栈”结构。从栈的操作特性上来看，栈是一种“操作受限”的线性表，只允许在一端插入和删除数据。

那么相比数组和列表，栈只带给我们限制，而并没有任何优势，为什么还要使用呢？

事实上，从功能上来说，数组或链表确实可以替代栈，但特定的数据结构是对特定场景的抽象，而且，数组或链表暴露了太多操作接口，操作上灵活，但使用时不可控，自然就容易出错。

所以，当某个数据集合只涉及在一端插入和删除数据，并且满足后进先出和先进后出的特性时，就应该选择栈这种数据结构。

#### 如何实现一个栈？

有两种方式可以实现：用数组实现的顺序栈，和用链表实现的链式栈。

#### 时间与空间复杂度

不管是顺序栈和链式栈，我们存储数据都只需要一个大小为ｎ的数组就够了，在入栈和出栈操作时只需要一两个临时变量存储空间，所以空间复杂度为O(1)

**注意**：对于空间复杂度的分析，是指除了原本的数据存储空间外，算法运行还需要的额外的存储空间，而不是说存储数据需要一个大小为ｎ的数组，空间复杂度就为O(n)

时间复杂度：不管是顺序栈还是链式栈，入栈和出栈都只涉及栈顶和个别数据的操作，所以时间复杂度为O(1)

#### 支持动态扩容的顺序栈

其实实现方法和数组动态扩容类似：即只需要底层依赖支持一个支持动态扩容的数组即可，当栈满了之后，我们就申请一个更大的数组，将原来的数据搬移到新数组。

那么支持动态扩容的顺序栈，如何分析时间复杂度呢？

对于出栈操作来说，不涉及内存重新申请和数据搬移，所以时间复杂度仍为O(1)

但是对于入栈操作来说，当占中有剩余空间时，时间复杂度仍为O(1)；但是当空间不够时，就需要重新申请内存和数据搬移，所以时间复杂度就成为O(n)

#### 栈在函数调用中的应用

操作系统为每个线程分配一块独立的内存空间，这块空间被组织成为栈这种结构，用来存储函数调用时的临时变量，每进入一个函数，就会将临时变量作为一个栈帧入栈，当被调用的函数完成返回之后，将这个函数对应的栈帧出栈

#### 栈在表达式求值中的应用

对于只包含加减乘除的四则运算，如何实现表达式求值呢？

实际上，编译器是通过两个栈来实现的。其中一个保存操作数的栈，另一个保存运算符的栈。从左向右遍历表达式，当遇到数字，直接压入操作数栈，当遇到运算符，就与运算符栈的栈顶元素进行比较。

如果比运算符栈顶元素优先级高，就将当前运算符压入栈；如果低，就从运算符栈顶取出运算符，并从操作数栈顶取出两个操作数，然后进行计算，再把计算完的结果压入操作数，继续比较。

#### 栈在括号匹配中的应用

#### 解答开篇：如何实现浏览器的前进和后退功能？

我们使用两个栈，Ｘ和Ｙ，把首次浏览的页面依次压入栈Ｘ，当点击后退按钮时，再依次从栈Ｘ中出栈，并将出栈的数据依次放入Ｙ。当点击前进按钮时，依次从Ｙ中取出数据，放入Ｘ中，当X中没有数据时，就说明没有页面可以继续后退浏览了，当栈Ｙ中没有数据，就说明没有页面可以点击前进浏览了。

### 队列：队列在线程池等有限资源池中的应用

#### 什么是队列？

1. 先进者先出，这就是典型的“队列”结构。
2. 支持两个操作：入队enqueue()，放一个数据到队尾；出队dequeue()，从队头取一个元素。
3. 所以，和栈一样，队列也是一种操作受限的线性表

#### 如何实现对列？

**队列API**

```
public interface Queue<T> {
public void enqueue(T item); //入队
public T dequeue(); //出队
public int size(); //统计元素数量
public boolean isNull(); //是否为空
}
```

**数组实现（顺序队列）**：对于栈来说，只需要一个栈顶指针就可以了，但是队列需要两个指针：一个head指针，指向队头，一个tail指针，指向队尾。

但是和数组一样，当tail移动到队尾，即数组中没有空闲空间时，就无法继续添加数据了，那么该如何解决呢？

和数组一样，每次出队相当于删除数组中下标为０的数据，要搬移整个队列的数据，这样出队的时间复杂度就会从Ｏ(1)变为Ｏ(n)，如何优化呢？

实际上，在出队时不需要搬移数据，如果没有空闲空间了，只需要在入队是集中进行一次搬移操作。

**链表实现（链式队列)**

基于链表的实现，我们同样需要两个指针：head 指针和 tail 指针。它们分别指向链表的第一个结点和最后一个结点。

```
入队时，tail->next= new_node, tail=tail->next
出队时，head=head->next
```

**循环队列（基于数组）**

循环队列可以成功避免数据搬移的操作，实现循环队列的关键是：确定好队空的队满的判定条件。

在实现非循环的队列时，队满`tail=n`，队空`head=tail`

实现循环队列时，队空仍为`head=tail`，队满为`(tail+1)%n=head`

#### 队列有哪些常见的应用？
**阻塞队列**
在队列的基础上增加阻塞操作，就成了阻塞队列。

阻塞队列就是在队列为空的时候，从队头取数据会被阻塞，因为此时还没有数据可取，直到队列中有了数据才能返回；如果队列已经满了，那么插入数据的操作就会被阻塞，直到队列中有空闲位置后再插入数据，然后在返回。

从上面的定义可以看出这就是一个“生产者-消费者模型”。这种基于阻塞队列实现的“生产者-消费者模型”可以有效地协调生产和消费的速度。当“生产者”生产数据的速度过快，“消费者”来不及消费时，存储数据的队列很快就会满了，这时生产者就阻塞等待，直到“消费者”消费了数据，“生产者”才会被唤醒继续生产。不仅如此，基于阻塞队列，我们还可以通过协调“生产者”和“消费者”的个数，来提高数据处理效率，比如配置几个消费者，来应对一个生产者。
**并发队列**

在多线程的情况下，会有多个线程同时操作队列，这时就会存在线程安全问题。能够有效解决线程安全问题的队列就称为并发队列。

并发队列简单的实现就是在enqueue()、dequeue()方法上加锁，但是锁粒度大并发度会比较低，同一时刻仅允许一个存或取操作。

实际上，基于数组的循环队列利用CAS原子操作，可以实现非常高效的并发队列。这也是循环队列比链式队列应用更加广泛的原因。

#### 线程池资源枯竭时的处理
在资源有限的场景，当没有空闲资源时，基本上都可以通过“队列”这种数据结构来实现请求排队。
#### 思考
除了线程池这种池结构会用到队列排队请求，还有哪些类似线程池结构或者场景中会用到队列的排队请求呢？

今天讲到并发队列，关于如何实现无锁的并发队列，网上有很多讨论。对这个问题，你怎么看？

### 递归：如何用三行代码找到“最终推荐人”？（极客10）

现在很多ａｐｐ都有推荐注册返佣金的功能，在这个功能中，用户Ａ推荐Ｂ来注册，用户Ｂ推荐C来注册，我们可以说，用户C的最终推荐人为Ａ，用户Ｂ也是A，而A没有最终推荐人。

基于这个背景：给定一个用户ID，如何查找这个用户的最终推荐人？

#### 如何理解递归？

递归：可以理解为去的过程叫递，回来的过程叫归（结合极客10给出的例子）

基本上，所有的递归问题都可以用递推公式来解决。

#### 递归需要满足的三个条件

* 一个问题的解可以分为几个子问题的解
* 这个问题与分解之后的子问题，除了数据规模不同，求解思路完全一样。
* 存在递归终止条件

#### 如何编写递归代码？

最关键的就是：写出递推公式，找到终止条件，剩下的就是将递推公式转化为代码。

所以，写递归代码的关键是找到如何将大问题分解为小问题的规律，并且基于此写出递归公式，然后再推敲终止条件，最终将递推公式和终止条件翻译成代码。

这里有一个**思维上的误区**：对于递归代码，我们总想试图想清楚递和归过程的做法，实际上就是陷入了思维误区，很多时候我们理解吃力，是因为我们自己给自己制造了这种理解障碍

所以，遇到递归，我们就把他抽象成为一个递推公式，不要想一层层的调用关系，不要试图用人脑去分解递归的每个步骤。

#### 递归代码要警惕堆栈溢出

#### 递归代码要警惕重复计算

#### 如何将递归代码改写为非递归代码？

**最后，递归代码虽然简洁高效，但是递归代码也有很多弊端，比如：堆栈溢出、重复计算、函数调用耗时多、空间复杂度高等，所以，在编写递归代码时，一定要控制好这些副作用！**

### 排序（一）：冒泡，插入，选择O(n^2)－－均基于比较

#### 几种经典排序算法及其时间复杂度级别
冒泡、插入、选择 O(n^2) 基于比较
快排、归并 O(nlogn) 基于比较
计数、基数、桶 O(n) 不基于比较

#### 如何分析一个排序算法？
1. 学习排序算法的思路？明确原理、掌握实现以及分析性能。

2. 如何分析排序算法性能？从执行效率、内存消耗以及稳定性3个方面分析排序算法的性能。

3. 执行效率：从以下3个方面来衡量
   * 最好情况、最坏情况、平均情况时间复杂度
   * 时间复杂度的系数、常数、低阶：排序的数据量比较小时考虑
   * 比较次数和交换（或移动）次数

4. 内存消耗：通过空间复杂度来衡量。针对排序算法的空间复杂度，引入原地排序的概念，原地排序算法就是指空间复杂度为O(1)的排序算法。

5. 稳定性：如果待排序的序列中存在值等的元素，经过排序之后，相等元素之间原有的先后顺序不变，就说明这个排序算法时稳定的。

#### 冒泡排序
1. 排序原理

   * 冒泡排序只会操作相邻的两个数据。
   * 对相邻两个数据进行比较，看是否满足大小关系要求，若不满足让它俩互换
   * 一次冒泡会让至少一个元素移动到它应该在的位置，重复n次，就完成了n个数据的排序工作。
   * 优化：若某次冒泡不存在数据交换，则说明已经达到完全有序，所以终止冒泡。

2. 性能分析

   执行效率：最小时间复杂度、最大时间复杂度、平均时间复杂度

   * 最小时间复杂度：数据完全有序时，只需进行一次冒泡操作即可，时间复杂度是O(n)。
   * 最大时间复杂度：数据倒序排序时，需要n次冒泡操作，时间复杂度是O(n^2)。
   * 平均时间复杂度：通过有序度和逆序度来分析。

   空间复杂度：每次交换仅需1个临时变量，故空间复杂度为O(1)，是原地排序算法。
   算法稳定性：如果两个值相等，就不会交换位置，故是稳定排序算法。

**什么是有序度？**

有序度是数组中具有有序关系的元素对的个数，比如[2,4,3,1,5,6]这组数据的有序度就是11，即：24,23,25,26,45,46,35,36,15,16,56。同理，对于一个倒序数组，比如[6,5,4,3,2,1]，有序度是0；对于一个完全有序的数组，比如[1,2,3,4,5,6]，有序度为n*(n-1)/2。也就是15，完全有序的情况称为满有序度。
什么是逆序度？逆序度的定义正好和有序度相反。**核心公式：逆序度=满有序度-有序度**。
排序过程，就是有序度增加，逆序度减少的过程，最后达到满有序度，就说明排序完成了。
冒泡排序包含两个操作原子，即比较和交换，每交换一次，有序度加1。不管算法如何改进，交换的次数总是确定的，即逆序度。
对于包含n个数据的数组进行冒泡排序，平均交换次数是多少呢？*

最坏的情况初始有序度为0，所以要进行n*(n-1)/2交换。最好情况下，初始状态有序度是n*(n-1)/2，就不需要进行交互。我们可以取个中间值n*(n-1)/4，来表示初始有序度既不是很高也不是很低的平均情况。*

换句话说，平均情况下，需要n*(n-1)/4次交换操作，比较操作肯定比交换操作多，而复杂度的上限是O(n^2)，所以**平均情况时间复杂度就是O(n^2)**。
以上的分析并不严格，但很实用，这就够了。

#### 插入排序
1. 算法原理
   首先，我们将数组中的数据分为2个区间，即已排序区间和未排序区间。初始已排序区间只有一个元素，就是数组的第一个元素。插入算法的核心思想就是取未排序区间中的元素，在已排序区间中找到合适的插入位置将其插入，并保证已排序区间中的元素一直有序。重复这个过程，直到未排序中元素为空，算法结束
2. 性能分析
   * 时间复杂度：最好、最坏、平均情况
     如果要排序的数组已经是有序的，我们并不需要搬移任何数据。只需要遍历一遍数组即可，所以时间复杂度是O(n)。如果数组是倒序的，每次插入都相当于在数组的第一个位置插入新的数据，所以需要移动大量的数据，因此时间复杂度是O(n^2)。而在一个数组中插入一个元素的平均时间复杂度是O(n)，插入排序需要n次插入，所以平均时间复杂度是O(n^2)。

   * 空间复杂度：从上面的代码可以看出，插入排序算法的运行并不需要额外的存储空间，所以空间复杂度是O(1)，是原地排序算法。

   * 算法稳定性：在插入排序中，对于值相同的元素，我们可以选择将后面出现的元素，插入到前面出现的元素的后面，这样就保持原有的顺序不变，所以是稳定的。

#### 希尔排序

希尔排序也是一种**插入排序**，它是简单插入排序经过改进之后的一个更高效的版本，也称为缩小增量排序，同时该算法是冲破O(n2）的第一批算法之一。

1. 基本思想

   希尔排序是把记录按下标的一定增量分组，对每组使用直接插入排序算法排序；随着增量逐渐减少，每组包含的关键词越来越多，当增量减至1时，整个文件恰被分成一组，算法便终止。

   希尔排序在数组中采用跳跃式分组的策略，通过某个增量将数组元素划分为若干组，然后分组进行插入排序，随后逐步缩小增量，继续按组进行插入排序操作，直至增量为1。希尔排序通过这种策略使得整个数组在初始阶段达到从宏观上看基本有序，小的基本在前，大的基本在后。然后缩小增量，到增量为1时，其实多数情况下只需微调即可，不会涉及过多的数据移动。

2. 基本步骤

   * 原始数组：８,9,1,7,2,3,5,4,6,0	初始增量设为：gap=length/2=5
   * 这样，整个数组被分为５组，将这五组分别进行直接插入排序
   * 然后缩小增量：gap=gap/2=2，这样数组被分为２组，继续直接插入排序
   * 再缩小增量，此时gap=gap/2=1，整个数组就变为一组了
   * 最后做简单微调即可

   3. 这种增量选择我们可以用一个序列来表示，{n/2,(n/2)/2...1}，称为**增量序列**。希尔排序的增量序列的选择与证明是个数学难题，我们选择的这个增量序列是比较常用的，也是希尔建议的增量，称为希尔增量，但其实这个增量序列不是最优的。

#### 选择排序

1. 算法原理
   选择排序算法也分已排序区间和未排序区间。但是选择排序每次会从未排序区间中找到最小的元素，并将其放置到已排序区间的末尾.
2. 性能分析
   * 时间复杂度：最好、最坏、平均情况
     选择排序的最好、最坏、平均情况时间复杂度都是O(n^2)。为什么？因为无论是否有序，每个循环都会完整执行，没得商量。
   * 空间复杂度：
     选择排序算法空间复杂度是O(1)，是一种原地排序算法。
   * 算法稳定性：
     选择排序算法不是一种稳定排序算法，比如[5,8,5,2,9]这个数组，使用选择排序算法第一次找到的最小元素就是2，与第一个位置的元素5交换位置，那第一个5和中间的5的顺序就变量，所以就不稳定了。正因如此，相对于冒泡排序和插入排序，选择排序就稍微逊色了。

#### 思考
1. 冒泡排序和插入排序的时间复杂度都是 O(n^2)，都是原地排序算法，为什么插入排序要比冒泡排序更受欢迎呢？
   冒泡排序移动数据有3条赋值语句，而选择排序的交换位置的只有1条赋值语句，因此在有序度相同的情况下，冒泡排序时间复杂度是选择排序的3倍，所以，选择排序性能更好。

2. 如果数据存储在链表中，这三种排序算法还能工作吗？如果能，那相应的时间、空间复杂度又是多少呢？

#### 总结

**冒泡，插入，选择**：时间复杂度都是O(n^2)，比较高，适合小规模数据的排序。

### 排序（二）：快速，归并O(nlogn)－－均基于比较

#### 分治思想
1. 分治思想：分治，顾明思意，就是分而治之，将一个大问题分解成小的子问题来解决，小的子问题解决了，大问题也就解决了。

2. 分治与递归的区别：分治算法一般都用递归来实现的。分治是一种解决问题的处理思想，递归是一种编程技巧。

#### 归并排序
1. 算法原理
   先把数组从中间分成前后两部分，然后对前后两部分分别进行排序，再将排序好的两部分合并到一起，这样整个数组就有序了。这就是归并排序的核心思想。

   如何用递归实现归并排序呢？写递归代码的技巧就是分写得出递推公式，然后找到终止条件，最后将递推公式翻译成递归代码。递推公式怎么写？如下
   递推公式：merge_sort(p…r) = merge(merge_sort(p…q), merge_sort(q+1…r))
   终止条件：p >= r 不用再继续分解

2. 性能分析

   * 算法稳定性：
     归并排序稳不稳定关键要看merge()函数，也就是两个子数组合并成一个有序数组的那部分代码。在合并的过程中，如果 A[p…q] 和 A[q+1…r] 之间有值相同的元素，那我们就可以像伪代码中那样，先把 A[p…q] 中的元素放入tmp数组，这样 就保证了值相同的元素，在合并前后的先后顺序不变。所以，归并排序是一种稳定排序算法。

   * 时间复杂度：

     分析归并排序的时间复杂度就是分析递归代码的时间复杂度
     **如何分析递归代码的时间复杂度？**
     递归的适用场景是一个问题a可以分解为多个子问题b、c，那求解问题a就可以分解为求解问题b、c。问题b、c解决之后，我们再把b、c的结果合并成a的结果。若定义求解问题a的时间是T(a)，则求解问题b、c的时间分别是T(b)和T(c)，那就可以得到这样的递推公式：T(a) = T(b) + T(c) + K，其中K等于将两个子问题b、c的结果合并成问题a的结果所消耗的时间。

     这里有一个重要的结论：不仅递归求解的问题可以写成递推公式，递归代码的时间复杂也可以写成递推公式。套用这个公式，那么归并排序的时间复杂度就可以表示为：
     T(1) = C； n=1 时，只需要常量级的执行时间，所以表示为 C。
     T(n) = 2*T(n/2) + n； n>1，其中n就是merge()函数合并两个子数组的的时间复杂度O(n)。
     T(n) = 2*T(n/2) + n
       = 2*(2*T(n/4) + n/2) + n = 4*T(n/4) + 2*n
       = 4*(2*T(n/8) + n/4) + 2*n = 8*T(n/8) + 3*n
       = 8*(2*T(n/16) + n/8) + 3*n = 16*T(n/16) + 4*n
       ......
       = 2^k * T(n/2^k) + k * n
       ......
     当T(n/2^k)=T(1) 时，也就是 n/2^k=1，我们得到k=log2n。将k带入上面的公式就得到T(n)=Cn+nlog2n。如用大O表示法，T(n)就等于O(nlogn)。所以，**归并排序的时间复杂度就是O(nlogn)**。

   * 空间复杂度：

     **归并排序算法不是原地排序算法，空间复杂度是O(n)**
     为什么？因为归并排序的合并函数，在合并两个数组为一个有序数组时，需要借助额外的存储空间。为什么空间复杂度是O(n)而不是O(nlogn)呢？如果我们按照分析递归的时间复杂度的方法，通过递推公式来求解，那整个归并过程需要的空间复杂度就是O(nlogn)，但这种分析思路是有问题的！因为，在实际上，递归代码的空间复杂度并不是像时间复杂度那样累加，而是这样的过程，即在每次合并过程中都需要申请额外的内存空间，但是合并完成后，临时开辟的内存空间就被释放掉了，在任意时刻，CPU只会有一个函数在执行，也就只会有一个临时的内存空间在使用。临时空间再大也不会超过n个数据的大小，所以空间复杂度是O(n)。

3. 注意：

* divide：将数组划分为两个子数组，第一个子数组的元素个数x1=n/2(x1为大于等于n/2的最小整数)，第二个子数组的元素个数x2=n/2(x2为小于于等于n/2的最大整数)
* 重点在合并而不是分割：全部分割完成之后，一次合并称为一趟归并排序

4. **求解归并趟数**：m个元素k路归并的归并趟数s=logk(m)

#### 快速排序
1. 算法原理
   快排的思想是这样的：如果要排序数组中下标从p到r之间的一组数据，我们选择p到r之间的任意一个数据作为pivot（分区点），**一般选择最后一个数据作为分区点**。然后遍历p到r之间的数据，将小于pivot的放到左边，将大于pivot的放到右边，将povit放到中间。经过这一步之后，数组p到r之间的数据就分成了3部分，前面p到q-1之间都是小于povit的，中间是povit，后面的q+1到r之间是大于povit的。根据分治、递归的处理思想，我们可以用递归排序下标从p到q-1之间的数据和下标从q+1到r之间的数据，直到区间缩小为1，就说明所有的数据都有序了。
   递推公式：quick_sort(p…r) = quick_sort(p…q-1) + quick_sort(q+1, r)
   终止条件：p >= r

2. **快排简便分析方法：**

   （5,2,6,3,8）为例：以５为基准，**从右向左**，大于５不交换，小于５则与５交换，所以第一步完成之后为（３，２，６，５，８）；

   第一步是走到３开始交换，这次从３开始**从左往右**开始，遇到大于５交换，小于５不交换，所以交换６和５，为（３，２，５，６，８），第一趟结束。。

3. 性能分析
   * 算法稳定性：**不稳定**
     因为分区过程中涉及交换操作，如果数组中有两个8，其中一个是pivot，经过分区处理后，后面的8就有可能放到了另一个8的前面，先后顺序就颠倒了，所以快速排序是不稳定的排序算法。比如数组[1,2,3,9,8,11,8]，取后面的8作为pivot，那么分区后就会将后面的8与9进行交换。
   * 时间复杂度：最好、最坏、平均情况
     快排也是用递归实现的，所以时间复杂度也可以用递推公式表示。
     如果每次分区操作都能正好把数组分成大小接近相等的两个小区间，那快排的时间复杂度递推求解公式跟归并的相同。
     T(1) = C； n=1 时，只需要常量级的执行时间，所以表示为 C。
     T(n) = 2*T(n/2) + n； n>1
     所以，**快排的时间复杂度也是O(nlogn)**。
     但是，如果数组中的元素原来已经有序了，比如1，3，5，6，8，若每次选择最后一个元素作为pivot，那每次分区得到的两个区间都是不均等的，需要进行大约n次的分区，才能完成整个快排过程，而每次分区我们平均要扫描大约n/2个元素，**这种情况下，快排的时间复杂度就是O(n^2)**。
     前面两种情况，一个是分区及其均衡，一个是分区极不均衡，它们分别对应了快排的最好情况时间复杂度和最坏情况时间复杂度。那快排的平均时间复杂度是多少呢？T(n)大部分情况下是O(nlogn)，只有在极端情况下才是退化到O(n^2)，而且我们也有很多方法将这个概率降低。
   * 空间复杂度：快排是一种原地排序算法，空间复杂度是O(1)

#### 归并排序与快速排序的区别
归并和快排用的都是分治思想，递推公式和递归代码也非常相似，那它们的区别在哪里呢？

1. 归并排序，是先递归调用，再进行合并，合并的时候进行数据的交换。所以它是自下而上的排序方式。何为自下而上？就是先解决子问题，再解决父问题。

2. 快速排序，是先分区，在递归调用，分区的时候进行数据的交换。所以它是自上而下的排序方式。何为自上而下？就是先解决父问题，再解决子问题。

#### 思考

1. O(n)时间复杂度内求无序数组中第K大元素？比如4，2，5，12，3这样一组数据，第3大元素是4。
   我们选择数组区间A[0...n-1]的最后一个元素作为pivot，对数组A[0...n-1]进行原地分区，这样数组就分成了3部分，A[0...p-1]、A[p]、A[p+1...n-1]。
   如果如果p+1=K，那A[p]就是要求解的元素；如果K>p+1，说明第K大元素出现在A[p+1...n-1]区间，我们按照上面的思路递归地在A[p+1...n-1]这个区间查找。同理，如果K<p+1，那我们就在A[0...p-1]区间查找。
   时间复杂度分析？
   第一次分区查找，我们需要对大小为n的数组进行分区操作，需要遍历n个元素。第二次分区查找，我们需要对大小为n/2的数组执行分区操作，需要遍历n/2个元素。依次类推，分区遍历元素的个数分别为n、n/2、n/4、n/8、n/16......直到区间缩小为1。如果把每次分区遍历的元素个数累加起来，就是等比数列求和，结果为2n-1。所以，上述解决问题的思路为O(n)。

2. 有10个访问日志文件，每个日志文件大小约为300MB，每个文件里的日志都是按照时间戳从小到大排序的。现在需要将这10个较小的日志文件合并为1个日志文件，合并之后的日志仍然按照时间戳从小到大排列。如果处理上述任务的机器内存只有1GB，你有什么好的解决思路能快速地将这10个日志文件合并？

   思路：

   先构建十条io流，分别指向十个文件，每条io流读取对应文件的第一条数据，然后比较时间戳，选择出时间戳最小的那条数据，将其写入一个新的文件，然后指向该时间戳的io流读取下一行数据，然后继续刚才的操作，比较选出最小的时间戳数据，写入新文件，io流读取下一行数据，以此类推，完成文件的合并， 这种处理方式，日志文件有n个数据就要比较n次，每次比较选出一条数据来写入，时间复杂度是O（n），空间复杂度是O（1）,几乎不占用内存。

#### 总结

归并和快速排序，都是利用分治思想，代码都通过递归实现。

理解归并的重点是递推公式和merge()合并函数，同理理解快排的重点是理解递推公式和partition()函数。

归并排序是一种在任何情况下都比较稳定的排序算法，但是这也使他存在致命的缺点，即归并排序不是原地排序，空间复杂度较高，是O(n)，正因为如此，没有快排应用广泛。

快排虽然在最坏情况下的时间复杂度为O(n^2)，但是平均时间复杂度都是O(nlogn)，而且快排时间复杂度退化到O(n^2)的概率非常小，我们可以通过合理选择pivot来避免这种情况的发生。

### 排序（三）：桶，计数，基数O(n)－－不基于比较

#### 线性排序算法介绍
1. 线性排序算法包括桶排序、计数排序、基数排序。

2. 线性排序算法的时间复杂度为O(n)。

3. 此3种排序算法都不涉及元素之间的比较操作，是非基于比较的排序算法。

4. 对排序数据的要求很苛刻，**重点掌握此3种排序算法的适用场景**。

#### 桶排序（Bucket sort）
1. 算法原理：
   * 将要排序的数据分到几个**有序的桶**里，每个桶里的数据再单独进行快速排序。
   * 桶内排完序之后，再把每个桶里的数据按照顺序依次取出，组成的序列就是有序的了。

2. 使用条件
   * 要排序的数据需要很容易就能划分成m个桶，并且桶与桶之间有着天然的大小顺序。
   * 数据在各个桶之间分布是均匀的。

3. 适用场景
   * 桶排序比较适合用在外部排序中。
   * 外部排序就是数据存储在外部磁盘且数据量大，但内存有限无法将整个数据全部加载到内存中。

4. 应用案例
   * 需求描述：
     有10GB的订单数据，需按订单金额（假设金额都是正整数）进行排序
     但内存有限，仅几百MB
   * 解决思路：
     扫描一遍文件，看订单金额所处数据范围，比如1元-10万元，那么就分100个桶。
     第一个桶存储金额1-1000元之内的订单，第二个桶存1001-2000元之内的订单，依次类推。
     每个桶对应一个文件，并按照金额范围的大小顺序编号命名（00，01，02，…，99）。
     将100个小文件依次放入内存并用快排排序。
     所有文件排好序后，只需按照文件编号从小到大依次读取每个小文件并写到大文件中即可。
   * **注意点**：若单个文件无法全部载入内存，则针对该文件继续按照前面的思路进行处理即可。

#### 计数排序（Counting sort）
1. 算法原理
   * 计数其实就是桶排序的一种特殊情况。
   * 当要排序的n个数据所处范围并不大时，比如最大值为k，则分成k个桶
   * 每个桶内的数据值都是相同的，就省掉了桶内排序的时间。

2. 案例分析：
   假设只有8个考生分数在0-5分之间，成绩存于数组A[8] = [2，5，3，0，2，3，0，3]。
   使用大小为6的数组C[6]表示桶，下标对应分数，即0，1，2，3，4，5。
   C[6]存储的是考生人数，只需遍历一边考生分数，就可以得到C[6] = [2，0，2，3，0，1]。
   对C[6]数组顺序求和则C[6]=[2，2，4，7，7，8]，c[k]存储的是小于等于分数k的考生个数。
   数组R[8] = [0，0，2，2，3，3，3，5]存储考生名次。那么如何得到R[8]的呢？
   从后到前依次扫描数组A，比如扫描到3时，可以从数组C中取出下标为3的值7，也就是说，到目前为止，包括自己在内，分数小于等于3的考生有7个，也就是说3是数组R的第7个元素（也就是数组R中下标为6的位置）。当3放入数组R后，小于等于3的元素就剩下6个了，相应的C[3]要减1变成6。
   以此类推，当扫描到第二个分数为3的考生时，就会把它放入数组R中第6个元素的位置（也就是下标为5的位置）。当扫描完数组A后，数组R内的数据就是按照分数从小到大排列的了。

3. 使用条件
   * 只能用在数据范围不大的场景中，若数据范围k比要排序的数据n大很多，就不适合用计数排序；
   * 计数排序只能给非负整数排序，其他类型需要在不改变相对大小情况下，转换为非负整数；
   * 比如如果考试成绩精确到小数后一位，就需要将所有分数乘以10，转换为整数。

#### 基数排序（Radix sort）
1. 算法原理（以排序10万个手机号为例来说明）
   1）比较两个手机号码a，b的大小，如果在前面几位中a已经比b大了，那后面几位就不用看了。
   2）借助稳定排序算法的思想，可以先按照最后一位来排序手机号码，然后再按照倒数第二位来重新排序，以此类推，最后按照第一个位重新排序。
   3）经过11次排序后，手机号码就变为有序的了。
   4）每次排序有序数据范围较小，可以使用桶排序或计数排序来完成。

2. 使用条件
   * 要求数据可以分割独立的“位”来比较；
   * 位之间由递进关系，如果a数据的高位比b数据大，那么剩下的地位就不用比较了；
   * 每一位的数据范围不能太大，要可以用线性排序，否则基数排序的时间复杂度无法做到O(n)。

#### 思考
1. 如何根据年龄给100万用户数据排序？

   思路：根据年龄个１００万用户排序就类似按照成绩给５０万考生排序。

   假设年龄范围最小为１，最大不超过１２０，我们可以遍历这１００万用户，根据年龄将其划分到这１２０个桶中，然后依次顺序遍历这１２０个桶中的元素，这样就得到了按照年龄排序的１００万用户数据。

2. 对D，a，F，B，c，A，z这几个字符串进行排序，要求将其中所有小写字母都排在大写字母前面，但是小写字母内部和大写字母内部不要求有序。比如经过排序后为a，c，z，D，F，B，A，这个如何实现呢？如果字符串中处理大小写，还有数字，将数字放在最前面，又该如何解决呢？

   思路：利用桶排序思想，弄小写，大写，数字三个桶，遍历一遍，都放进去，然后再从桶中取出来就行了。相当于遍历了两遍，复杂度O(n)。

#### 总结

这三种线性排序对要排序的数据有比较严苛的要求，应用不是很广泛，我们主要掌握他们的应用场景，而不要去想排序的实现过程。

但是如果数据特征比较符合这些排序算法，应用他们会非常高效，线性时间复杂度可以达到O(n)

桶排序和计数排序思想非常类似，都是针对范围不大的数据，将数据划分为不同的桶来实现排序。

基数排序要求数据可以划分成高地位，位之间有递进关系。比较两个数，我们只需要比较高位，高位相同的再比较地位，而且每一位的数据范围不能太大，因为**基数排序算法需要借助桶排序和计数排序来完成每一个位的操作**。

### 排序（四）：如何实现一个通用的高性能的排序函数？

#### 如何选择合适的排序算法？

1. 排序算法一览表
   ​                 时间复杂度 是稳定排序？ 是原地排序？
   冒泡排序 O(n^2) 是 是
   插入排序 O(n^2) 是 是
   选择排序 O(n^2) 否 是
   快速排序 O(nlogn) 否 是 
   归并排序 O(nlogn) 是 否
   桶排序 O(n) 是 否
   计数排序 O(n+k)，k是数据范围 是 否
   基数排序 O(dn)，d是纬度 是 否

#### 为什选择快速排序？
1. 线性排序时间复杂度很低但使用场景特殊，如果要写一个通用排序函数，不能选择线性排序。
2. 为了兼顾任意规模数据的排序，一般会首选时间复杂度为O(nlogn)的排序算法来实现排序函数。
3. 同为O(nlogn)的快排和归并排序相比，归并排序不是原地排序算法，所以最优的选择是快排。

#### 如何优化快速排序？
导致快排时间复杂度降为O(n^2)的原因是**分区点选择不合理**，最理想的分区点是：被分区点分开的两个分区中，数据的数量差不多。如何优化分区点的选择？

有2种常用方法，如下：

1. 三数取中法
   * 从区间的首、中、尾分别取一个数，然后比较大小，取中间值作为分区点
   * 如果要排序的数组比较大，那“三数取中”可能就不够用了，可能要“5数取中”或者“10数取中”。

2. 随机法：每次从要排序的区间中，随机选择一个元素作为分区点。

3. 警惕快排的递归发生堆栈溢出，

   有2中解决方法，如下：

   * 限制递归深度，一旦递归超过了设置的阈值就停止递归。
   * 在堆上模拟实现一个函数调用栈，手动模拟递归压栈、出栈过程，这样就没有系统栈大小的限制。

#### 通用排序函数实现技巧
1. 数据量不大时，可以采取用空间换时间的思路
2. 数据量大时，优化快排分区点的选择
3. 防止堆栈溢出，可以选择在堆上手动模拟调用栈解决
4. 在排序区间中，当元素个数小于某个常数时，可以考虑使用O(n^2)级别的插入排序。因为O表示的是一个趋势，而不是实际的执行时间，所以可以把函数画在坐标轴上，当数据量较小时，O(n^2)也可能小于O(nlogn)，所以对于小规模数据的排序，我们选择不需要递归，比较简单的插入排序算法。
5. 用哨兵简化代码，每次排序都减少一次判断，尽可能把性能优化到极致

### 横向比较总结

#### 常用排序算法的性能与待排数组的排序顺序的关系作一个总结：

* 冒泡：无关，初始排序对原始的冒泡排序没有影响，但对改进后的冒泡排序(即加标志位的冒泡排序)有很大影响。
* 选择：无关,选择排序是每次选最小（大）的数放入到另一个容器中，因此每次都要比较所有的数才能得到最小（大）的数，所以和初始状态无关。
* 插入：有关，有序程度越大，比较越少；
* shell：有关，它的基本思想基于插入排序；
* 合并：有关，有序程度愈大，合并过程的比较次数越少；（不确定）
* 归并排序：从每个组含两个数、四个数。。。一直到只有一组，合并组的方法是两组内比较选最小（大）的放新组的前头，所以也是和初始状态无关的。（不确定）
* 堆排序：有关，有序程度越大，建立堆下沉操作越少；
* 快排序：（１）有关，如果选择最后值作为阀值，那么有序程度越好，就越可能退化成O(n^2)；（２）无关，随机选择阀值，那么与排序程度无关。

#### 采用简单选择排序,比较次数与移动次数分别为()

简单选择排序它最大的特点是交换移动数据次数相当少，这样也就节约了相应的时间，无论最好最坏的情况，**其比较次数都是一样多**。

第 i 次排序需要进行n-i 次关键字的比较，此时需要比较n-1+n-2+...+1=n(n-1)/2次，时间复杂度为O（n^2)。

对于交换次数而言，当最好的时候，交换为0次，最差的时候，也就初始排序，交换次数为n-1次,复杂度为O（n)。

#### 每个算法的特点：

* 冒泡和选择：每一趟都能确定一个元素的最终位置
* 归并：第一趟排序结束都可以得到若干个有序子序列
* 插入：在每趟排序后能确定前面的若干元素是有序的